{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "import torch\n",
    "from data_gen_1D import Generator\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the Wasserstein distance between two 1D distributions, 'a' and 'b,' with weights 'wa' and 'wb.'\n",
    "# The parameter 'p' defines which Wasserstein distance is calculated. For 'p=1,' the result is the 1-Wasserstein distance, and for 'p=2,' the output is the 2-Wasserstein distance.\n",
    "\n",
    "def wasserstein_distance(a, b, wa, wb):\n",
    "        \n",
    "    W_dist = ot.wasserstein_1d(a, b, wa, wb, p = 1)\n",
    "\n",
    "    return W_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This funciton evaluetes the Z_score.\n",
    "\n",
    "def Z_score(H0, t1):\n",
    "    \n",
    "    if t1 <= torch.max(H0):\n",
    "        p_value = (torch.count_nonzero(H0 >= t1) + 1)/(torch.tensor(H0.size()) + 1)\n",
    "\n",
    "    if t1 > torch.max(H0):\n",
    "        p_value = 1/(torch.tensor(H0.size()) + 1)\n",
    "        \n",
    "    return torch.tensor(norm.ppf(1-p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots and saves the distributions of the Wasserstein distances and prints the Z_score on the plot.\n",
    "\n",
    "def Plotter(W_dist_calibration, W_dist, color, label, save):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (7, 7))\n",
    "\n",
    "    ax.set_title('Wasserstein distance', fontsize = 20)\n",
    "    ax.set_xlabel('$W_{1}$', fontsize = 15)\n",
    "    ax.set_ylabel('Density', fontsize = 15)\n",
    "\n",
    "    z_score = Z_score(W_dist_calibration, torch.median(W_dist))\n",
    "    anchored_text_test = AnchoredText('$Z_{score}$:'+str('%.3f' % z_score.item()), bbox_to_anchor = (1, 0.85), bbox_transform = ax.transAxes, loc = 'right')\n",
    "\n",
    "    ax.hist(W_dist_calibration, bins = 'auto', color = color[0], density = True, label = 'ref-'+str(label[0]), alpha = 0.5)\n",
    "    ax.hist(W_dist, bins = 'auto', color = color[1], density = True, label = 'ref-'+str(label[1]), alpha = 0.5)\n",
    "    ax.legend()\n",
    "\n",
    "    ax.add_artist(anchored_text_test)\n",
    "\n",
    "    if save:\n",
    "\n",
    "        fig.savefig(f'./LPC_Plot/W_dist_{label}.pdf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1000\n",
    "\n",
    "# Number of signal events.\n",
    "NS = 0\n",
    "# Size of background sample.\n",
    "NR = 2000\n",
    "\n",
    "# Size of reference sample.\n",
    "N_R = 200000\n",
    "\n",
    "# Here, I define the tensors where I will store the results.\n",
    "W_dist_calibration = torch.zeros(iteration)\n",
    "W_dist = torch.zeros(iteration)\n",
    "\n",
    "# These are the different classes.\n",
    "classes = ['NP1', 'NP2', 'NP3', 'NP4']\n",
    "\n",
    "# This array represents the values of 'NS' and 'NR' for the different classes.\n",
    "values = [[10, 1990], [110, 1890], [80, 1920], [0, 2000]]\n",
    "\n",
    "# This parameter defines whether to save the plots or not.\n",
    "save = True\n",
    "Pois_ON = False\n",
    "\n",
    "st = time.time()\n",
    "l = 0\n",
    "\n",
    "for sig_type in classes:\n",
    "    \n",
    "    for seed in range(iteration):\n",
    "\n",
    "        # Here, I generate two samples using the Generator and then evaluete the Wasserstein distance. In this case the samples belong to the same class 'ref'.\n",
    "        ref, data = Generator(seed, NS, NR, N_R, 'ref', Pois_ON)\n",
    "        W_dist_calibration[seed] = wasserstein_distance(torch.squeeze(ref), torch.squeeze(data), torch.ones(ref.size(0))/ref.size(0), torch.ones(data.size(0))/data.size(0))\n",
    "\n",
    "        # Here, I generate two new samples using the Generator and then evaluete the Wasserstein distance. In this case the forst sample belongs to the class 'ref' and the second to the class sig_type.\n",
    "        ref, data_true  = Generator(seed + int(1e6), values[l][0], values[l][1], N_R, sig_type, Pois_ON)\n",
    "        W_dist[seed] = wasserstein_distance(torch.squeeze(ref), torch.squeeze(data_true), torch.ones(ref.size(0))/ref.size(0), torch.ones(data_true.size(0))/data_true.size(0))\n",
    "    \n",
    "    Plotter(W_dist_calibration, W_dist, ['#ff7f0e', '#2ca02c'], ['ref', sig_type], save)\n",
    "    l = l+1\n",
    "\n",
    "et = time.time()\n",
    "\n",
    "print(f'Computational time: {et-st} s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
