{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "82dd22b2-c4bd-4c0e-aba1-11231faafe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.transforms as mtransforms\n",
    "from pytorchtools_classifier import EarlyStopping\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR\n",
    "from matplotlib.offsetbox import AnchoredText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd6dce64-9d30-4c68-bb40-a8f9772995c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ef7d63bb-3dd0-44e4-9911-9b528fb931f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "\n",
    "    def __init__(self,p, kernel_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.NN = nn.Sequential(\n",
    "          \n",
    "            nn.Linear(48, 1000, dtype = torch.float, device = device),\n",
    "            nn.BatchNorm1d(1000, dtype = torch.float),\n",
    "            nn.Dropout1d(p = p),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(1000, 700, dtype = torch.float, device = device),\n",
    "            nn.BatchNorm1d(700, dtype = torch.float),\n",
    "            nn.Dropout1d(p = p),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(700, 75, dtype = torch.float, device = device),\n",
    "            nn.BatchNorm1d(75, dtype = torch.float),\n",
    "            nn.Dropout1d(p = p),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(75, 1, dtype = torch.float,  device = device),\n",
    "        )\n",
    "        \n",
    "        #self._init_weights(self.NN)\n",
    "        #nn.Sequential.apply(_init_weights)\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self,module):\n",
    "        \n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, 0, 0.1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.fill_(0.08)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.NN(x)\n",
    "\n",
    "        return torch.squeeze(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e48a4686-831f-4f25-bcb6-5ac4cbed32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reg_Loss(loss, LAMBDA):\n",
    "    \n",
    "    l_reg = 0\n",
    "    for W in model.parameters():\n",
    "        l_reg = l_reg + torch.norm(W, 1)\n",
    "    \n",
    "    loss_reg = loss + LAMBDA*l_reg\n",
    "    \n",
    "    return loss_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2d586e9b-e624-46a1-aa6c-ab52799ec493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targets = torch.load(\"/home/gbortolai/Thesis/data/Jets/Classifier/dataset_train\", map_location = device)\n",
    "validation, validation_targets = torch.load(\"/home/gbortolai/Thesis/data/Jets/Classifier/dataset_validation\", map_location = device)\n",
    "test, test_targets = torch.load(\"/home/gbortolai/Thesis/data/Jets/Classifier/dataset_test\", map_location = device)\n",
    "\n",
    "\n",
    "train = train.to(torch.float).view(train.size(0), 1, train.size(1), train.size(2))\n",
    "validation = validation.to(torch.float).view(validation.size(0), 1, validation.size(1), validation.size(2))\n",
    "test = test.to(torch.float).view(test.size(0), 1, test.size(1), test.size(2))\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "n_batches_train = int(train.size(0)/batch_size)\n",
    "train = torch.stack(torch.chunk(train, n_batches_train, dim = 0), dim = 0)\n",
    "train_targets = torch.stack(torch.chunk(train_targets, n_batches_train, dim = 0), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ed4ece-a2e4-4456-8d47-fb61a6565fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 27.933262).  Saving model ...\n",
      "Validation loss decreased (27.933262 --> 11.353431).  Saving model ...\n",
      "Validation loss decreased (11.353431 --> 6.065214).  Saving model ...\n",
      "Validation loss decreased (6.065214 --> 4.349742).  Saving model ...\n",
      "Validation loss decreased (4.349742 --> 3.776112).  Saving model ...\n",
      "Validation loss decreased (3.776112 --> 3.196090).  Saving model ...\n",
      "Validation loss decreased (3.196090 --> 3.146622).  Saving model ...\n",
      "Validation loss decreased (3.146622 --> 2.904224).  Saving model ...\n",
      "Validation loss decreased (2.904224 --> 2.614577).  Saving model ...\n",
      "Validation loss decreased (2.614577 --> 2.510371).  Saving model ...\n",
      "Validation loss decreased (2.510371 --> 2.072216).  Saving model ...\n",
      "Validation loss decreased (2.072216 --> 1.923597).  Saving model ...\n",
      "Validation loss decreased (1.923597 --> 1.627644).  Saving model ...\n",
      "Validation loss decreased (1.627644 --> 1.412050).  Saving model ...\n",
      "Validation loss decreased (1.412050 --> 1.300494).  Saving model ...\n",
      "Validation loss decreased (1.300494 --> 1.181706).  Saving model ...\n",
      "Validation loss decreased (1.181706 --> 1.145714).  Saving model ...\n",
      "Validation loss decreased (1.145714 --> 1.107754).  Saving model ...\n",
      "Validation loss decreased (1.107754 --> 1.079919).  Saving model ...\n",
      "Validation loss decreased (1.079919 --> 1.076385).  Saving model ...\n",
      "Validation loss decreased (1.076385 --> 1.067950).  Saving model ...\n",
      "Validation loss decreased (1.067950 --> 1.061367).  Saving model ...\n",
      "Validation loss decreased (1.061367 --> 1.036756).  Saving model ...\n",
      "Validation loss decreased (1.036756 --> 1.014252).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Validation loss decreased (1.014252 --> 1.005583).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Validation loss decreased (1.005583 --> 0.997653).  Saving model ...\n",
      "Validation loss decreased (0.997653 --> 0.994082).  Saving model ...\n",
      "Validation loss decreased (0.994082 --> 0.969237).  Saving model ...\n",
      "Validation loss decreased (0.969237 --> 0.965366).  Saving model ...\n",
      "Validation loss decreased (0.965366 --> 0.960981).  Saving model ...\n",
      "Validation loss decreased (0.960981 --> 0.948129).  Saving model ...\n",
      "Validation loss decreased (0.948129 --> 0.934386).  Saving model ...\n",
      "Validation loss decreased (0.934386 --> 0.926819).  Saving model ...\n",
      "Validation loss decreased (0.926819 --> 0.914532).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Validation loss decreased (0.914532 --> 0.913447).  Saving model ...\n",
      "Validation loss decreased (0.913447 --> 0.902348).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Validation loss decreased (0.902348 --> 0.895969).  Saving model ...\n",
      "Validation loss decreased (0.895969 --> 0.884393).  Saving model ...\n",
      "Validation loss decreased (0.884393 --> 0.883623).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Validation loss decreased (0.883623 --> 0.878830).  Saving model ...\n",
      "Validation loss decreased (0.878830 --> 0.875440).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Validation loss decreased (0.875440 --> 0.871096).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "EarlyStopping counter: 3 out of 30\n",
      "EarlyStopping counter: 4 out of 30\n",
      "EarlyStopping counter: 5 out of 30\n",
      "EarlyStopping counter: 6 out of 30\n",
      "EarlyStopping counter: 7 out of 30\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Validation loss decreased (0.871096 --> 0.867345).  Saving model ...\n",
      "Validation loss decreased (0.867345 --> 0.867013).  Saving model ...\n",
      "Validation loss decreased (0.867013 --> 0.860219).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Validation loss decreased (0.860219 --> 0.857578).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Validation loss decreased (0.857578 --> 0.855653).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 30\n",
      "EarlyStopping counter: 2 out of 30\n",
      "EarlyStopping counter: 3 out of 30\n",
      "EarlyStopping counter: 4 out of 30\n",
      "EarlyStopping counter: 5 out of 30\n",
      "EarlyStopping counter: 6 out of 30\n"
     ]
    }
   ],
   "source": [
    "learing_rate = 1e-3\n",
    "patience = 30\n",
    "iteration = int(1e3)\n",
    "LAMBDA = 1e-3\n",
    "p = 0.3\n",
    "\n",
    "\n",
    "model = Classifier(p, 2)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = learing_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 30, gamma = 0.7)\n",
    "early_stopping = EarlyStopping(patience = patience, verbose = True)\n",
    "\n",
    "fig = plt.figure(figsize = (14, 7), constrained_layout=False)\n",
    "gs = GridSpec(1, 2, figure = fig)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 0])\n",
    "ax3.set_title('Loss train average')\n",
    "ax3.set_ylabel('Loss train average')\n",
    "ax3.set_ybound(lower = 0, upper = None)\n",
    "\n",
    "ax4 = fig.add_subplot(gs[0, 1])\n",
    "ax4.set_title('Loss validation average')\n",
    "ax4.set_ylabel('Loss validation average')\n",
    "ax4.set_ybound(lower = 0, upper = None)\n",
    "\n",
    "counter_train = 0\n",
    "counter_validation = 0\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "\n",
    "for ite in range(iteration):\n",
    "    model.train()\n",
    "    \n",
    "    for batch in range(n_batches_train):\n",
    "        \n",
    "        train_out = model(train[batch]).to(device)\n",
    "        loss_train = criterion(train_out, train_targets[batch])\n",
    "        loss_train_reg = Reg_Loss(loss_train, LAMBDA)\n",
    "        loss_train_reg = loss_train_reg.double()\n",
    "        train_losses.append(loss_train_reg.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_train_reg.requires_grad_()\n",
    "        loss_train_reg.backward(retain_graph = True)\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        \n",
    "    ax3.scatter(ite + 1, np.average(train_losses), s = 5, color = 'b')\n",
    "    train_losses = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    validation_out = model(validation).to(device)\n",
    "    loss_validation = criterion(validation_out, validation_targets)\n",
    "    loss_validation_reg = Reg_Loss(loss_validation, LAMBDA)\n",
    "    \n",
    "    ax4.scatter(ite + 1, loss_validation_reg.cpu().detach().numpy(), color = 'b', s = 5)\n",
    "    \n",
    "    early_stopping(loss_validation_reg, model)\n",
    "    if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "            \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9de77abf-35f0-49d2-8d62-7c804891b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for the class 1 is: 0.0\n",
      "The accuracy for the class 2 is: 0.0\n",
      "The accuracy for the class 3 is: 0.0\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/home/gbortolai/Thesis/Checkpoint/checkpoint_classifier.pth\"))\n",
    "\n",
    "model.eval()\n",
    "test_out = model(test).to(device)\n",
    "loss_test = criterion(test_out, test_targets)\n",
    "loss_test_reg = Reg_Loss(loss_test, LAMBDA)\n",
    "\n",
    "for i in [1,2,3]:\n",
    "\n",
    "    print(f\"The accuracy for the class {i} is: {(torch.count_nonzero(test_out == i)/torch.count_nonzero(test_targets == i))*100}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "269f4b91-d4c4-459a-8a1e-bdc29db6bef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1705, 2.3650, 2.3768,  ..., 2.3595, 2.3644, 1.6936],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71edba90-2a73-4333-b454-e463ecab8f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7aec8-712b-4a60-889f-ed32669ed400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a879e28-665d-4d84-86d7-5b7bc67485ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gbortolai_env_PyTorch-GPU]",
   "language": "python",
   "name": "conda-env-gbortolai_env_PyTorch-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
