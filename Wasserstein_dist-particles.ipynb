{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pAoZXn9f1l1B"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gbortolai/Thesis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-G-qK2XS1mIR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1679911409550,
     "user": {
      "displayName": "Gabriele Bortolai",
      "userId": "15239002622481471658"
     },
     "user_tz": -120
    },
    "id": "qtYHvqH51nTO",
    "outputId": "11300733-0304-45e6-e3b6-632f7429b4f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_dist(data_source, data_target):#1-Wasserstein\n",
    "\n",
    "#     ind1 = torch.stack([data_source[:,1], data_source[:,2]], dim = -1)#aggiunto ora\n",
    "#     ind2 = torch.stack([data_target[:,1], data_target[:,2]], dim = -1)#aggiunto ora\n",
    "    \n",
    "#     ind1 = ind1.double()\n",
    "#     ind2 = ind2.double()\n",
    "    \n",
    "    source = data_source[:,0]/torch.sum(data_source[:,0], dtype = torch.double)#.to(device)\n",
    "    target = data_target[:,0]/torch.sum(data_target[:,0], dtype = torch.double)#.to(device)\n",
    "    \n",
    "    source = source.to(device)\n",
    "    target = target.to(device)\n",
    "    \n",
    "    M = ot.dist(torch.stack([data_source[:,1], data_source[:,2]], dim = -1), torch.stack([data_target[:,1], data_target[:,2]], dim = -1), metric = 'euclidean').to(device)\n",
    "    \n",
    "    T = ot.emd(source, target, M).to(device)\n",
    "    W = torch.sum(T*M).to(device)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YvVlokaQ1Tfe"
   },
   "outputs": [],
   "source": [
    "jets, targets = torch.load('data/Jets/dataset_test', map_location = device)\n",
    "jets = jets.to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2248470,
     "status": "ok",
     "timestamp": 1679916152421,
     "user": {
      "displayName": "Gabriele Bortolai",
      "userId": "15239002622481471658"
     },
     "user_tz": -120
    },
    "id": "wm_ikfLX16J9",
    "outputId": "0b077717-a671-422c-9e4a-8f8b3bfaefa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "riga n: 0.0\n",
      "riga n: 0.06666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Wasserstein distance \n",
    "\n",
    "size = jets.size(0)\n",
    "\n",
    "Wasserstein_dist=torch.zeros(size, size, dtype = torch.double).to(device)\n",
    "\n",
    "for i in range (size):\n",
    "    for j in filter(lambda h: h>i, range (size)):\n",
    "        Wasserstein_dist[i][j] = wasserstein_dist(jets[i], jets[j]).to(device)\n",
    "    print('riga n:',(i/size)*100)\n",
    "#Wasserstein_dist = Wasserstein_dist/torch.max(Wasserstein_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "RblJqJ3z6FlT"
   },
   "outputs": [],
   "source": [
    "torch.save([Wasserstein_dist, targets],'data/Jets/Wasserstein_dist_test_s='+str(size))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:gbortolai_env_PyTorch-GPU]",
   "language": "python",
   "name": "conda-env-gbortolai_env_PyTorch-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
