{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pAoZXn9f1l1B"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gbortolai/Thesis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-G-qK2XS1mIR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import ot\n",
    "from multiprocessing import Pool\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1679911409550,
     "user": {
      "displayName": "Gabriele Bortolai",
      "userId": "15239002622481471658"
     },
     "user_tz": -120
    },
    "id": "qtYHvqH51nTO",
    "outputId": "11300733-0304-45e6-e3b6-632f7429b4f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliced_wasserstein_dist(a,b):\n",
    "    \n",
    "    source = a[torch.nonzero(a, as_tuple = False)[:,0], torch.nonzero(a, as_tuple = False)[:,1]].view(torch.nonzero(a, as_tuple = False).size(0)).float()\n",
    "    target = b[torch.nonzero(b, as_tuple = False)[:,0], torch.nonzero(b, as_tuple = False)[:,1]].view(torch.nonzero(b, as_tuple = False).size(0)).float()\n",
    "    \n",
    "    source = torch.unsqueeze(source, dim = 1)\n",
    "    target = torch.unsqueeze(target, dim = 1)\n",
    "    \n",
    "    source = source.to(device)\n",
    "    target = target.to(device)\n",
    "    \n",
    "    W = ot.sliced.sliced_wasserstein_distance(source, target, p = 2).to(device)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(data_source, data_target, ind1, ind2):\n",
    "    \n",
    "    SW = torch.zeros(data_source.size(0), data_target.size(0))\n",
    "    \n",
    "    if ind1 == ind2:\n",
    "        for i in range(data_source.size(0)):\n",
    "            for j in filter(lambda h: h>i, range(data_target.size(0))):\n",
    "\n",
    "                SW[i][j] = sliced_wasserstein_dist(data_source[i], data_target[j])\n",
    "                \n",
    "    elif ind2 > ind1:\n",
    "        \n",
    "        for i in range(data_source.size(0)):\n",
    "            for j in range(data_target.size(0)):\n",
    "                \n",
    "                SW[i][j] = sliced_wasserstein_dist(data_source[i], data_target[j])\n",
    "            \n",
    "    return SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterable(data, processes):\n",
    "    \n",
    "    data = torch.stack(torch.chunk(data, processes, dim = 0), dim = 0)\n",
    "    \n",
    "    for i in range(data.size(0)):\n",
    "        for j in range(data.size(0)):\n",
    "            \n",
    "            yield([data[i], data[j], i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YvVlokaQ1Tfe"
   },
   "outputs": [],
   "source": [
    "data, targets = torch.load('data/Jets/dataset_train')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = data.size(0)\n",
    "\n",
    "size = 100\n",
    "\n",
    "processes = 2\n",
    "\n",
    "Sliced_Wasserstein_dist = torch.zeros(size, size)\n",
    "\n",
    "ite = iterable(data[:size], processes)\n",
    "\n",
    "st = time.time()\n",
    "with Pool(processes = processes) as p:\n",
    "\n",
    "    Sliced_Wasserstein_dist = torch.cat(torch.chunk(torch.cat(p.starmap(fun, ite), dim = 1), processes, dim = 1), dim = 0)\n",
    "    \n",
    "et = time.time()\n",
    "print(et - st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(Sliced_Wasserstein_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2248470,
     "status": "ok",
     "timestamp": 1679916152421,
     "user": {
      "displayName": "Gabriele Bortolai",
      "userId": "15239002622481471658"
     },
     "user_tz": -120
    },
    "id": "wm_ikfLX16J9",
    "outputId": "0b077717-a671-422c-9e4a-8f8b3bfaefa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows done: 0.0 %\n",
      "Rows done: 2.5 %\n",
      "Rows done: 5.0 %\n",
      "Rows done: 7.5 %\n",
      "Rows done: 10.0 %\n",
      "Rows done: 12.5 %\n",
      "Rows done: 15.0 %\n",
      "Rows done: 17.5 %\n",
      "Rows done: 20.0 %\n",
      "Rows done: 22.5 %\n",
      "Rows done: 25.0 %\n",
      "Rows done: 27.500000000000004 %\n",
      "Rows done: 30.0 %\n",
      "Rows done: 32.5 %\n",
      "Rows done: 35.0 %\n",
      "Rows done: 37.5 %\n",
      "Rows done: 40.0 %\n",
      "Rows done: 42.5 %\n",
      "Rows done: 45.0 %\n",
      "Rows done: 47.5 %\n",
      "Rows done: 50.0 %\n",
      "Rows done: 52.5 %\n",
      "Rows done: 55.00000000000001 %\n",
      "Rows done: 57.49999999999999 %\n",
      "Rows done: 60.0 %\n",
      "Rows done: 62.5 %\n",
      "Rows done: 65.0 %\n",
      "Rows done: 67.5 %\n",
      "Rows done: 70.0 %\n",
      "Rows done: 72.5 %\n",
      "Rows done: 75.0 %\n",
      "Rows done: 77.5 %\n",
      "Rows done: 80.0 %\n",
      "Rows done: 82.5 %\n",
      "Rows done: 85.0 %\n",
      "Rows done: 87.5 %\n",
      "Rows done: 90.0 %\n",
      "Rows done: 92.5 %\n",
      "Rows done: 95.0 %\n",
      "Rows done: 97.5 %\n",
      "29.99451780319214\n"
     ]
    }
   ],
   "source": [
    "# #Wasserstein distance \n",
    "size = data.size(0)\n",
    "# size = 200\n",
    "\n",
    "Sliced_Wasserstein_dist=torch.zeros(size, size, dtype = torch.float).to(device)\n",
    "\n",
    "for i in range (size):\n",
    "    for j in filter(lambda h: h>i, range (size)):\n",
    "        Sliced_Wasserstein_dist[i][j] = sliced_wasserstein_dist(data[i], data[j]).to(device)\n",
    "    if i%5 == 0:\n",
    "        print(f'Rows done: {(i/size)*100} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RblJqJ3z6FlT"
   },
   "outputs": [],
   "source": [
    "torch.save([Sliced_Wasserstein_dist, targets],'data/Jets/Sliced_Wasserstein_dist_train_simple_s='+str(size))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:gbortolai_env_PyTorch-GPU]",
   "language": "python",
   "name": "conda-env-gbortolai_env_PyTorch-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
